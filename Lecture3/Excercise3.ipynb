{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "## You are given, as the train data, trn_x and trn_y along with their class labels trn_x_class and trn_y_class. The task is to classify the following TEST data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train data\n",
    "train_x = np.loadtxt(\"dataset1_G_noisy_ASCII/trn_x.txt\")\n",
    "train_x_label = np.loadtxt(\"dataset1_G_noisy_ASCII/trn_x_class.txt\")\n",
    "\n",
    "train_y = np.loadtxt(\"dataset1_G_noisy_ASCII/trn_y.txt\")\n",
    "train_y_label = np.loadtxt(\"dataset1_G_noisy_ASCII/trn_y_class.txt\")\n",
    "\n",
    "# Test data\n",
    "test_x = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_x.txt\")\n",
    "test_x_label = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_x_class.txt\")\n",
    "\n",
    "test_y = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_y.txt\")\n",
    "test_y_label = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_y_class.txt\")\n",
    "\n",
    "test_y_126 = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_y_126.txt\")\n",
    "test_y_126_label = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_y_126_class.txt\")\n",
    "\n",
    "test_xy = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_xy.txt\")\n",
    "test_xy_label = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_xy_class.txt\")\n",
    "\n",
    "test_xy_126 = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_xy_126.txt\")\n",
    "test_xy_126_label = np.loadtxt(\"dataset1_G_noisy_ASCII/tst_xy_126_class.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we see that our input features is 2-dimensional, i.e., it has two values per data point.\n",
    "Furthermore, x has label 1 and y has label 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the training data by plotting a 2D scatter plot and corresponding Gaussians for class x and class y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: look at: https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(train_x[:,0], train_x[:,1])\n",
    "#plt.plot(train_y[:,0], train_y[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) classify instances in tst_xy, and use the corresponding label file tst_xy_class to calculate the accuracy;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the statistics of x and y (use np.mean and np.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.61931577  0.22651021]\n",
      "[[ 2.67373236 -0.00766618]\n",
      " [-0.00766618  0.07231472]]\n",
      "[ 0.45262897 -0.63788186]\n",
      "[[ 0.32252417 -0.02634358]\n",
      " [-0.02634358  0.52652025]]\n"
     ]
    }
   ],
   "source": [
    "# x statistics\n",
    "train_x_mean = np.mean(train_x, axis=0)\n",
    "print(train_x_mean)\n",
    "train_x_cov = np.cov(train_x, rowvar=False)\n",
    "print(train_x_cov)\n",
    "#print(train_x_cov)\n",
    "# y statistics\n",
    "train_y_mean = np.mean(train_y, axis=0)\n",
    "train_y_cov = np.cov(train_y, rowvar=False)\n",
    "print(train_y_mean)\n",
    "print(train_y_cov)\n",
    "# priors\n",
    "prior_x = len(train_x)/(len(train_x)+len(train_y))\n",
    "prior_y = len(train_y)/(len(train_x)+len(train_y))\n",
    "#print(prior_x, prior_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function for computing the likelihood of x and y given our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define likelihood function\n",
    "# Implement your own or look on stack overflow if you are lazy - most important thing is that you understand what is going on\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "def likelihood(data, mean, cov):\n",
    "    likelihood_value = mvn.pdf(data, mean, cov)\n",
    "    return likelihood_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify the test data we compute the likelihood of it being class x and class y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute likelihood of x and y\n",
    "likelihood_x = likelihood(test_xy, train_x_mean, train_x_cov)\n",
    "likelihood_y = likelihood(test_xy, train_y_mean, train_y_cov)\n",
    "\n",
    "\n",
    "#plt.scatter(test_x[:,0],test_x[:,1],likelihood_x)\n",
    "#plt.scatter(test_y[:,0],test_y[:,1],likelihood_y)\n",
    "#plt.show()\n",
    "#print(likelihood_x)\n",
    "#print(likelihood_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the posterior probability by taking the priors into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027\n",
      "2027\n"
     ]
    }
   ],
   "source": [
    "# Compute posteriors from likelihood and prior\n",
    "posterior_x = likelihood_x * prior_x\n",
    "posterior_y = likelihood_y * prior_y\n",
    "print(len(posterior_x))\n",
    "print(len(posterior_y))\n",
    "#print(posterior_x)\n",
    "#print(posterior_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose to classify our test data as belonging to the class with the highest posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that labels for x and y are are 1 and 2 respectively\n",
    "# classification = ?\n",
    "classification = np.where(posterior_x > posterior_y, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the accuracy of our classifications by taking the sum of correct predictions and divide by the total number of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092254563394179\n"
     ]
    }
   ],
   "source": [
    "# accuracy_xy = ?\n",
    "accuracy_xy = np.where(classification == test_xy_label, 1, 0)\n",
    "accuracy = np.sum(accuracy_xy)/len(accuracy_xy)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) classify instances in tst_xy_126 by assuming a uniform prior over the space of hypotheses, and use the corresponding label file tst_xy_126_class to calculate the accuracy;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define our prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_x_uniform = 0.5\n",
    "prior_y_uniform = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute posteriors knowing that the posterior probability is simply the prior, p(C), multiplied by the likelihood p(x, C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_x_uniform = likelihood(test_xy_126 ,train_x_mean, train_x_cov)\n",
    "likelihood_y_uniform = likelihood(test_xy_126 ,train_y_mean, train_y_cov)\n",
    "\n",
    "posterior_x_uniform = likelihood_x_uniform * prior_x_uniform\n",
    "posterior_y_uniform = likelihood_y_uniform * prior_y_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have posteriors for both x and y we can classify the test data and compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using uniform prior 88.82%\n"
     ]
    }
   ],
   "source": [
    "classification_uniform = np.where(posterior_x_uniform > posterior_y_uniform, 1, 2)\n",
    "\n",
    "accuracy_xy_126_uniform = np.average(np.where(classification_uniform == test_xy_126_label, 1, 0))\n",
    "print(f\"Accuracy using uniform prior {accuracy_xy_126_uniform*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) classify instances in tst_xy_126 by assuming a prior probability of 0.9 for Class x and 0.1 for Class y, and use the corresponding label file tst_xy_126_class to calculate the accuracy; compare the results with those of (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simply follow the procedure of (b), however, this time with updated priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using non-uniform prior 96.27%\n"
     ]
    }
   ],
   "source": [
    "prior_x_non_uniform = 0.9\n",
    "prior_y_non_uniform = 0.1\n",
    "\n",
    "likelihood_x_non_uniform = likelihood(test_xy_126, train_x_mean, train_x_cov)\n",
    "likelihood_y_non_uniform = likelihood(test_xy_126, train_y_mean, train_y_cov)\n",
    "posterior_x_non_uniform = likelihood_x_non_uniform * prior_x_non_uniform\n",
    "posterior_y_non_uniform = likelihood_y_non_uniform * prior_y_non_uniform\n",
    "\n",
    "classification_non_uniform = np.where(posterior_x_non_uniform > posterior_y_non_uniform, 1, 2)\n",
    "\n",
    "accuracy_xy_126_non_uniform = np.average(np.where(classification_non_uniform == test_xy_126_label, 1, 0))\n",
    "\n",
    "print(f\"Accuracy using non-uniform prior {accuracy_xy_126_non_uniform*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the accuracy using uniform prior and non-uniform priors we see that using prior information about the data distribution improves classifcation accuracy by ?%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute improvement in accuracy 8.39%\n"
     ]
    }
   ],
   "source": [
    "improvement = (accuracy_xy_126_non_uniform / accuracy_xy_126_uniform) - 1\n",
    "print(f\"Absolute improvement in accuracy {improvement*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
