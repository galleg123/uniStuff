{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import multivariate_normal as norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complete_datasets(data_dict):\n",
    "    '''\n",
    "    Function for creating complete training and test sets containing\n",
    "    all classes.\n",
    "    '''\n",
    "    #Empty list\n",
    "    trainset = []\n",
    "    traintargets =[]\n",
    "    testset = []\n",
    "    testtargets =[]\n",
    "    \n",
    "    #For each class\n",
    "    for i in range(10):\n",
    "        trainset.append(data_dict[\"train%d\"%i])\n",
    "        traintargets.append(np.full(len(data_dict[\"train%d\"%i]),i))\n",
    "        testset.append(data_dict[\"test%d\"%i])\n",
    "        testtargets.append(np.full(len(data_dict[\"test%d\"%i]),i))\n",
    "    \n",
    "    #Concatenate into to complete datasets\n",
    "    trainset = np.concatenate(trainset)\n",
    "    traintargets = np.concatenate(traintargets)\n",
    "    testset = np.concatenate(testset)\n",
    "    testtargets = np.concatenate(testtargets)\n",
    "    return trainset, traintargets, testset, testtargets\n",
    "\n",
    "file = \"mnist_all.mat\"\n",
    "data = loadmat(file)\n",
    "\n",
    "#Complete training and test sets\n",
    "train_set, train_targets, test_set, test_targets = create_complete_datasets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 9\n",
    "\n",
    "#PCA\n",
    "\n",
    "def PCA_function(train_set,train_targets, value, pca):\n",
    "    train_pca = np.asarray([train_set[i] for i in range(len(train_targets)) if train_targets[i] == value])\n",
    "    transformed = pca.transform(train_pca)\n",
    "    return transformed\n",
    "\n",
    "pca = PCA(n_components=9)\n",
    "pca.fit(train_set)\n",
    "\n",
    "train_set_pca = [PCA_function(train_set, train_targets, i, pca) for i in range(10)]\n",
    "train_set_pca = np.asarray(train_set_pca, dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "#LDA\n",
    "\n",
    "def LDA_function(train_set, train_targets, value, lda):\n",
    "    train_lda = np.asarray([train_set[i] for i in range(len(train_targets)) if train_targets[i] == value])\n",
    "    transformed = lda.transform(train_lda)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "lda = LDA(n_components=9)\n",
    "lda.fit(train_set,train_targets)\n",
    "\n",
    "train_set_lda = [LDA_function(train_set, train_targets, i, lda) for i in range(10)]\n",
    "train_set_lda = np.asarray(train_set_lda, dtype=object)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMean(train_set):\n",
    "    mean = []\n",
    "    for i in range(10):\n",
    "        mean.append(np.mean(train_set[i],axis=0))\n",
    "    return mean\n",
    "\n",
    "def getCov(train_set):\n",
    "    cov = []\n",
    "    for i in range(10):\n",
    "        cov.append(np.cov(train_set[i],rowvar=False))\n",
    "    return cov\n",
    "\n",
    "def getPriors(train_targets):\n",
    "    priors = []\n",
    "    for i in range(10):\n",
    "        priors.append((train_targets==i).sum()/len(train_targets))\n",
    "    return priors\n",
    "\n",
    "priors = getPriors(train_targets)\n",
    "\n",
    "pca_means = getMean(train_set_pca)\n",
    "pca_covs = getCov(train_set_pca)\n",
    "\n",
    "lda_means = getMean(train_set_lda)\n",
    "lda_covs = getCov(train_set_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze proportion of Variance. If num_components=2 try to visualize dim. reduced data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Gaussians from PCA/LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA accuracy:  87.75\n",
      "LDA accuracy:  89.53\n"
     ]
    }
   ],
   "source": [
    "#Compute predictions\n",
    "test_set_pca = pca.transform(test_set)\n",
    "test_set_lda = lda.transform(test_set)\n",
    "\n",
    "def getPredictions(test_data, mean, cov, priors):\n",
    "    likelihood = [norm.pdf(test_data, mean[i], cov[i]) for i in range(10)]\n",
    "    posteriors = [likelihood[i]*priors[i] for i in range(10)]\n",
    "    predictions = np.argmax(posteriors, axis=0)\n",
    "    return predictions\n",
    "\n",
    "predictions_pca = getPredictions(test_set_pca, pca_means, pca_covs, priors)\n",
    "predictions_lda = getPredictions(test_set_lda, lda_means, lda_covs, priors)\n",
    "\n",
    "\n",
    "#Compute accuracy\n",
    "accuracy_pca = (np.where(predictions_pca == test_targets, 1, 0).sum()/len(test_targets))* 100\n",
    "accuracy_lda = (np.where(predictions_lda == test_targets,1,0).sum()/len(test_targets))* 100\n",
    "\n",
    "print(\"PCA accuracy: \", accuracy_pca)\n",
    "print(\"LDA accuracy: \", accuracy_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the confusion matrices for PCA and LDA\n",
    "\n",
    "pca_confusion = np.zeros((10,10))\n",
    "lda_confusion = np.zeros((10,10))\n",
    "\n",
    "\n",
    "\n",
    "#Plot Confusion matrices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
